本方案的核心在于使用 Redis Sorted Set (ZSet) 替代普通 Set，利用时间戳作为分数 (Score)，从而完美解决客户端非正常退出（断电、崩溃）导致的“僵尸种子”残留问题。

1. 核心架构
数据源：Chihaya Tracker -> Redis Stream (tracker:traffic)
消费者：后端服务（Go/Node/Python等） -> 消费 Stream -> 更新 Redis ZSet
存储结构：Redis ZSet (有序集合)
查询端：前端/API -> 直接读取 Redis ZSet
2. Redis 键名设计
我们按用户 (Passkey) 维度维护两个集合：

用途	Redis Key	数据结构	Member (成员)	Score (分数)
正在做种	tracker:user:seed:<passkey>	ZSet	infohash	ts (最后汇报时间戳)
正在下载	tracker:user:leech:<passkey>	ZSet	infohash	ts (最后汇报时间戳)
注：infohash 建议使用 40 位十六进制字符串，方便前端直接使用。

3. 消费者处理逻辑 (Consumer Logic)
消费者监听 tracker:traffic 流，获取每条消息的 passkey, infohash, left, event, ts 字段。

A. 核心判断流程
对每一条消息，执行以下原子操作（Pipeline）：

如果是停止事件 (event == stopped)：
动作：从做种和下载集合中彻底移除。
ZREM tracker:user:seed:<passkey> <infohash>
ZREM tracker:user:leech:<passkey> <infohash>
如果是完成事件 (event == completed)：
动作：从下载集合移除，加入做种集合。
ZREM tracker:user:leech:<passkey> <infohash>
ZADD tracker:user:seed:<passkey> <ts> <infohash>
其他情况 (started 或 none/update)：
判断 left 值：
若 left == 0 (做种中)：
ZADD tracker:user:seed:<passkey> <ts> <infohash> (更新心跳时间)
ZREM tracker:user:leech:<passkey> <infohash> (防御性清理，防止状态错乱)
若 left > 0 (下载中)：
ZADD tracker:user:leech:<passkey> <ts> <infohash> (更新心跳时间)
ZREM tracker:user:seed:<passkey> <infohash> (防御性清理)
B. 僵尸清理策略 (Zombie Cleanup)
这是本方案的精髓。客户端可能断电或断网，不会发送 stopped。我们需要根据 Score (时间戳) 自动剔除超时的种子。

超时阈值：建议设置为 announce_interval (30m) + 缓冲时间 (10m) = 40分钟 (2400秒)。
清理时机：
惰性清理（推荐）：每次查询该用户的列表前，先执行一次清理。
定期清理：后台跑定时任务扫描活跃用户。
清理命令：
bash
# 移除所有最后汇报时间早于 (当前时间 - 2400秒) 的种子
ZREMRANGEBYSCORE tracker:user:seed:<passkey> -inf <(now_ts - 2400)>
ZREMRANGEBYSCORE tracker:user:leech:<passkey> -inf <(now_ts - 2400)>
4. 查询接口实现
当 API 需要返回“用户正在做种的列表”时：

计算截止时间：expire_time = now() - 2400
清理过期数据： ZREMRANGEBYSCORE tracker:user:seed:<passkey> -inf <expire_time>
获取列表（按时间倒序，最近活跃的排前面）： ZREVRANGE tracker:user:seed:<passkey> 0 -1
统计数量： ZCARD tracker:user:seed:<passkey>
5. 伪代码示例 (Python风格)
python
def handle_traffic_event(event_data):
    passkey = event_data['passkey']
    infohash = event_data['infohash']
    left = int(event_data['left'])
    event = event_data['event']
    ts = int(event_data['ts']) # 消息产生的时间戳
    
    seed_key = f"tracker:user:seed:{passkey}"
    leech_key = f"tracker:user:leech:{passkey}"
    
    pipeline = redis.pipeline()
    
    if event == 'stopped':
        pipeline.zrem(seed_key, infohash)
        pipeline.zrem(leech_key, infohash)
    elif event == 'completed':
        pipeline.zrem(leech_key, infohash)
        pipeline.zadd(seed_key, {infohash: ts})
    else:
        # started 或 update
        if left == 0:
            pipeline.zadd(seed_key, {infohash: ts})
            pipeline.zrem(leech_key, infohash)
        else:
            pipeline.zadd(leech_key, {infohash: ts})
            pipeline.zrem(seed_key, infohash)
            
    # 可选：顺便清理该用户的过期数据（假设超时为 2400秒）
    expire_threshold = time.time() - 2400
    pipeline.zremrangebyscore(seed_key, '-inf', expire_threshold)
    pipeline.zremrangebyscore(leech_key, '-inf', expire_threshold)
    
    pipeline.execute()
总结
使用 Redis Streams 确保不漏掉任何状态变更。
使用 ZSet (Sorted Set) 记录最后活跃时间。
利用 ZREMRANGEBYSCORE 自动处理非正常退出的客户端。
双重清理（left=0 时清理 leech 集合，反之亦然）确保状态唯一。
这套方案是 PT 业界处理 Tracker 状态同步的标准最佳实践，既保证了高性能，又保证了数据的最终一致性。

